{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "977f02ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ TESTING FIXED ADVANCED SPRING DYNAMICS\n",
      "==================================================\n",
      "ðŸš€ ADVANCED SPRING DYNAMICS FEATURE SELECTION\n",
      "============================================================\n",
      "   Round 1: Selected Feature 11 (Spring: 0.878, Perf: 0.689, Div: 0.900)\n",
      "   Round 2: Selected Feature 8 (Spring: 0.926, Perf: 0.433, Div: 1.000)\n",
      "   Round 3: Selected Feature 7 (Spring: 0.357, Perf: 1.000, Div: 0.901)\n",
      "   Round 4: Selected Feature 4 (Spring: 0.262, Perf: 0.951, Div: 0.897)\n",
      "   Round 5: Selected Feature 10 (Spring: 0.288, Perf: 0.759, Div: 1.000)\n",
      "âœ… Selected 6 features with advanced criteria\n",
      "\n",
      "âœ… Successfully selected 6 features: [np.int64(11), np.int64(8), np.int64(7), np.int64(4), np.int64(10), np.int64(6)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.datasets import load_breast_cancer, load_diabetes, load_wine, load_iris\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import networkx as nx\n",
    "\n",
    "class AdvancedSpringFeatureSelector:\n",
    "    def __init__(self, \n",
    "                 performance_weight=0.3,\n",
    "                 diversity_weight=0.2,\n",
    "                 strong_threshold=0.6,\n",
    "                 selection_ratio=0.4,\n",
    "                 iterations=150):\n",
    "        \n",
    "        self.performance_weight = performance_weight\n",
    "        self.diversity_weight = diversity_weight\n",
    "        self.strong_threshold = strong_threshold\n",
    "        self.selection_ratio = selection_ratio\n",
    "        self.iterations = iterations\n",
    "        \n",
    "        self.positions = None\n",
    "        self.springs = []\n",
    "        self.correlations = None\n",
    "        self.feature_scores = None\n",
    "        self.selected_features = []\n",
    "        self.performance_metrics = {}\n",
    "        self.feature_explanations = {}\n",
    "    \n",
    "    def calculate_performance_scores(self, X, y, problem_type='classification'):\n",
    "        \"\"\"Calculate multiple performance metrics for each feature\"\"\"\n",
    "        n_features = X.shape[1]\n",
    "        performance_scores = np.zeros(n_features)\n",
    "        \n",
    "        for i in range(n_features):\n",
    "            if np.std(X[:, i]) > 0:\n",
    "                if problem_type == 'classification':\n",
    "                    # Correlation with target\n",
    "                    try:\n",
    "                        corr = abs(np.corrcoef(X[:, i], y)[0, 1])\n",
    "                    except:\n",
    "                        corr = 0\n",
    "                    # Mutual information\n",
    "                    try:\n",
    "                        mi = mutual_info_classif(X[:, i].reshape(-1, 1), y, random_state=42)[0]\n",
    "                    except:\n",
    "                        mi = 0\n",
    "                    # Simple model performance\n",
    "                    try:\n",
    "                        model = LogisticRegression(random_state=42)\n",
    "                        cv_score = cross_val_score(model, X[:, i].reshape(-1, 1), y, cv=3, scoring='accuracy').mean()\n",
    "                    except:\n",
    "                        cv_score = 0\n",
    "                    \n",
    "                    # Combined performance score\n",
    "                    performance_scores[i] = 0.4 * corr + 0.4 * mi + 0.2 * cv_score\n",
    "                else:\n",
    "                    # For regression\n",
    "                    try:\n",
    "                        corr = abs(np.corrcoef(X[:, i], y)[0, 1])\n",
    "                        performance_scores[i] = corr\n",
    "                    except:\n",
    "                        performance_scores[i] = 0\n",
    "        \n",
    "        # Normalize\n",
    "        max_score = np.max(performance_scores)\n",
    "        if max_score > 0:\n",
    "            performance_scores = performance_scores / max_score\n",
    "        \n",
    "        return performance_scores\n",
    "    \n",
    "    def calculate_diversity_scores(self, correlations, selected_mask=None):\n",
    "        \"\"\"Calculate diversity scores to avoid redundant features\"\"\"\n",
    "        n_features = correlations.shape[0]\n",
    "        diversity_scores = np.ones(n_features)\n",
    "        \n",
    "        if selected_mask is None:\n",
    "            selected_mask = np.zeros(n_features, dtype=bool)\n",
    "        \n",
    "        for i in range(n_features):\n",
    "            if not selected_mask[i]:\n",
    "                # Penalize features that are too similar to already selected features\n",
    "                similarity_to_selected = 0\n",
    "                if np.any(selected_mask):\n",
    "                    similarity_to_selected = np.max(correlations[i, selected_mask])\n",
    "                \n",
    "                # Also consider overall redundancy\n",
    "                high_correlations = np.sum(correlations[i] > 0.7) - 1  # -1 for self\n",
    "                \n",
    "                diversity_score = (1.0 - similarity_to_selected) * (1.0 / (1.0 + high_correlations * 0.1))\n",
    "                diversity_scores[i] = diversity_score\n",
    "        \n",
    "        # Normalize\n",
    "        max_score = np.max(diversity_scores)\n",
    "        if max_score > 0:\n",
    "            diversity_scores = diversity_scores / max_score\n",
    "        \n",
    "        return diversity_scores\n",
    "    \n",
    "    def run_spring_simulation(self, correlations):\n",
    "        \"\"\"Run the enhanced spring simulation\"\"\"\n",
    "        n_features = correlations.shape[0]\n",
    "        \n",
    "        # Initialize springs and positions\n",
    "        self.initialize_enhanced_springs(correlations)\n",
    "        self.initialize_positions(n_features)\n",
    "        \n",
    "        # Run simulation\n",
    "        for iteration in range(self.iterations):\n",
    "            self.update_dynamics_enhanced()\n",
    "            \n",
    "        return self.compute_spring_scores()\n",
    "    \n",
    "    def initialize_enhanced_springs(self, correlations):\n",
    "        \"\"\"Initialize springs with enhanced physics\"\"\"\n",
    "        n_features = correlations.shape[0]\n",
    "        self.springs = []\n",
    "        \n",
    "        for i in range(n_features):\n",
    "            for j in range(i + 1, n_features):\n",
    "                corr = abs(correlations[i, j])\n",
    "                \n",
    "                if corr > self.strong_threshold:\n",
    "                    # Strong correlation - compressed spring\n",
    "                    rest_length = 0.3 + 0.4 * (1 - (corr - self.strong_threshold) / (1 - self.strong_threshold))\n",
    "                    strength = 0.3 * corr\n",
    "                    spring_type = \"compressed\"\n",
    "                    color = 'red'\n",
    "                    width = 3 + 2 * corr\n",
    "                    \n",
    "                elif corr > 0.3:\n",
    "                    # Moderate correlation\n",
    "                    rest_length = 1.2\n",
    "                    strength = 0.1\n",
    "                    spring_type = \"neutral\" \n",
    "                    color = 'green'\n",
    "                    width = 1.5\n",
    "                    \n",
    "                else:\n",
    "                    # Weak correlation\n",
    "                    rest_length = 2.0\n",
    "                    strength = 0.05\n",
    "                    spring_type = \"extended\"\n",
    "                    color = 'blue'\n",
    "                    width = 1\n",
    "                \n",
    "                self.springs.append({\n",
    "                    'from': i, 'to': j, 'rest_length': rest_length,\n",
    "                    'strength': strength, 'type': spring_type,\n",
    "                    'correlation': corr, 'color': color, 'width': width\n",
    "                })\n",
    "    \n",
    "    def initialize_positions(self, n_features):\n",
    "        \"\"\"Initialize positions in 3D space\"\"\"\n",
    "        # Start with features in a sphere\n",
    "        indices = np.arange(n_features)\n",
    "        phi = np.arccos(1 - 2 * indices / n_features)\n",
    "        theta = np.pi * (1 + 5**0.5) * indices\n",
    "        \n",
    "        radius = 3.0\n",
    "        x = radius * np.sin(phi) * np.cos(theta)\n",
    "        y = radius * np.sin(phi) * np.sin(theta)\n",
    "        z = radius * np.cos(phi)\n",
    "        \n",
    "        self.positions = np.column_stack([x, y, z])\n",
    "        self.velocities = np.zeros_like(self.positions)\n",
    "        self.initial_positions = self.positions.copy()\n",
    "    \n",
    "    def update_dynamics_enhanced(self, dt=0.1, damping=0.9):\n",
    "        \"\"\"Enhanced dynamics update\"\"\"\n",
    "        forces = self.compute_forces_enhanced()\n",
    "        self.velocities += forces * dt\n",
    "        self.velocities *= damping\n",
    "        self.positions += self.velocities * dt\n",
    "    \n",
    "    def compute_forces_enhanced(self):\n",
    "        \"\"\"Compute enhanced forces with cluster preservation\"\"\"\n",
    "        n_features = len(self.positions)\n",
    "        forces = np.zeros_like(self.positions)\n",
    "        \n",
    "        # Spring forces\n",
    "        for spring in self.springs:\n",
    "            i, j = spring['from'], spring['to']\n",
    "            pos_i, pos_j = self.positions[i], self.positions[j]\n",
    "            \n",
    "            delta = pos_j - pos_i\n",
    "            distance = np.linalg.norm(delta)\n",
    "            \n",
    "            if distance > 0:\n",
    "                displacement = distance - spring['rest_length']\n",
    "                force_magnitude = spring['strength'] * displacement\n",
    "                \n",
    "                # Non-linear force for better convergence\n",
    "                if abs(displacement) > 1.0:\n",
    "                    force_magnitude *= 1.5\n",
    "                \n",
    "                force_direction = delta / distance\n",
    "                \n",
    "                forces[i] += force_direction * force_magnitude\n",
    "                forces[j] -= force_direction * force_magnitude\n",
    "        \n",
    "        # Smart repulsion\n",
    "        for i in range(n_features):\n",
    "            for j in range(i + 1, n_features):\n",
    "                delta = self.positions[j] - self.positions[i]\n",
    "                distance = np.linalg.norm(delta)\n",
    "                \n",
    "                if distance > 0:\n",
    "                    # Adaptive repulsion based on correlation\n",
    "                    corr = abs(self.correlations[i, j]) if self.correlations is not None else 0\n",
    "                    repulsion_strength = 0.1 / (1.0 + corr * 5)  # Less repulsion for correlated features\n",
    "                    repulsion_force = repulsion_strength / (distance ** 2 + 0.1)\n",
    "                    \n",
    "                    force_direction = delta / distance\n",
    "                    forces[i] -= force_direction * repulsion_force\n",
    "                    forces[j] += force_direction * repulsion_force\n",
    "        \n",
    "        return forces\n",
    "    \n",
    "    def compute_spring_scores(self):\n",
    "        \"\"\"Compute spring dynamics scores\"\"\"\n",
    "        n_features = len(self.positions)\n",
    "        \n",
    "        # Centrality score\n",
    "        distances = np.linalg.norm(self.positions, axis=1)\n",
    "        centrality_scores = 1.0 / (1.0 + distances)\n",
    "        \n",
    "        # Compression and connectivity scores\n",
    "        compression_scores = np.zeros(n_features)\n",
    "        connectivity_scores = np.zeros(n_features)\n",
    "        \n",
    "        for spring in self.springs:\n",
    "            if spring['type'] == \"compressed\":\n",
    "                i, j = spring['from'], spring['to']\n",
    "                actual_distance = np.linalg.norm(self.positions[i] - self.positions[j])\n",
    "                if actual_distance < spring['rest_length'] * 1.2:  # Actually compressed\n",
    "                    compression_scores[i] += spring['correlation']\n",
    "                    compression_scores[j] += spring['correlation']\n",
    "                    connectivity_scores[i] += 1\n",
    "                    connectivity_scores[j] += 1\n",
    "        \n",
    "        # Stability score\n",
    "        movement = np.linalg.norm(self.positions - self.initial_positions, axis=1)\n",
    "        stability_scores = 1.0 / (1.0 + movement)\n",
    "        \n",
    "        # Normalize scores\n",
    "        centrality_scores = centrality_scores / (np.max(centrality_scores) + 1e-8)\n",
    "        compression_scores = compression_scores / (np.max(compression_scores) + 1e-8)\n",
    "        connectivity_scores = connectivity_scores / (np.max(connectivity_scores) + 1e-8)\n",
    "        stability_scores = stability_scores / (np.max(stability_scores) + 1e-8)\n",
    "        \n",
    "        # Combine spring scores\n",
    "        spring_scores = (\n",
    "            0.3 * centrality_scores +\n",
    "            0.4 * compression_scores +\n",
    "            0.2 * connectivity_scores +\n",
    "            0.1 * stability_scores\n",
    "        )\n",
    "        \n",
    "        return spring_scores\n",
    "    \n",
    "    def select_features_advanced(self, X, y, problem_type='classification'):\n",
    "        \"\"\"Advanced feature selection with performance and diversity\"\"\"\n",
    "        self.correlations = self.calculate_correlations(X)\n",
    "        n_features = X.shape[1]\n",
    "        n_select = max(1, int(n_features * self.selection_ratio))\n",
    "        \n",
    "        print(\"ðŸš€ ADVANCED SPRING DYNAMICS FEATURE SELECTION\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Step 1: Run spring simulation\n",
    "        spring_scores = self.run_spring_simulation(self.correlations)\n",
    "        \n",
    "        # Step 2: Calculate performance scores\n",
    "        performance_scores = self.calculate_performance_scores(X, y, problem_type)\n",
    "        \n",
    "        # Step 3: Iterative selection with diversity\n",
    "        selected_features = []\n",
    "        selected_mask = np.zeros(n_features, dtype=bool)\n",
    "        \n",
    "        for round_num in range(n_select):\n",
    "            # Calculate diversity scores based on current selection\n",
    "            diversity_scores = self.calculate_diversity_scores(self.correlations, selected_mask)\n",
    "            \n",
    "            # Combined scores for this round\n",
    "            combined_scores = (\n",
    "                (1 - self.performance_weight - self.diversity_weight) * spring_scores +\n",
    "                self.performance_weight * performance_scores +\n",
    "                self.diversity_weight * diversity_scores\n",
    "            )\n",
    "            \n",
    "            # Select best feature not already chosen\n",
    "            available_scores = combined_scores.copy()\n",
    "            available_scores[selected_mask] = -np.inf  # Exclude already selected\n",
    "            \n",
    "            best_feature = np.argmax(available_scores)\n",
    "            selected_features.append(best_feature)\n",
    "            selected_mask[best_feature] = True\n",
    "            \n",
    "            if round_num < 5:  # Only print first 5 for brevity\n",
    "                print(f\"   Round {round_num + 1}: Selected Feature {best_feature} \"\n",
    "                      f\"(Spring: {spring_scores[best_feature]:.3f}, \"\n",
    "                      f\"Perf: {performance_scores[best_feature]:.3f}, \"\n",
    "                      f\"Div: {diversity_scores[best_feature]:.3f})\")\n",
    "        \n",
    "        self.selected_features = selected_features\n",
    "        self.feature_scores = combined_scores\n",
    "        \n",
    "        # Store performance metrics\n",
    "        self.performance_metrics = {\n",
    "            'spring_scores': spring_scores,\n",
    "            'performance_scores': performance_scores,\n",
    "            'diversity_scores': diversity_scores,\n",
    "            'final_scores': combined_scores\n",
    "        }\n",
    "        \n",
    "        print(f\"âœ… Selected {len(selected_features)} features with advanced criteria\")\n",
    "        return selected_features\n",
    "    \n",
    "    def calculate_correlations(self, data):\n",
    "        \"\"\"Calculate correlation matrix\"\"\"\n",
    "        try:\n",
    "            correlations = np.corrcoef(data.T)\n",
    "            np.fill_diagonal(correlations, 0)\n",
    "            return correlations\n",
    "        except:\n",
    "            try:\n",
    "                correlations = 1 - squareform(pdist(data.T, metric='correlation'))\n",
    "                np.fill_diagonal(correlations, 0)\n",
    "                return np.nan_to_num(correlations)\n",
    "            except:\n",
    "                # Fallback: simple correlation calculation\n",
    "                n_features = data.shape[1]\n",
    "                correlations = np.zeros((n_features, n_features))\n",
    "                for i in range(n_features):\n",
    "                    for j in range(n_features):\n",
    "                        if i != j:\n",
    "                            try:\n",
    "                                corr = np.corrcoef(data[:, i], data[:, j])[0, 1]\n",
    "                                correlations[i, j] = corr\n",
    "                            except:\n",
    "                                correlations[i, j] = 0\n",
    "                return correlations\n",
    "\n",
    "# Test the fixed implementation\n",
    "print(\"ðŸ”§ TESTING FIXED ADVANCED SPRING DYNAMICS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load a simple dataset first\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=100, n_features=20, n_informative=5, random_state=42)\n",
    "\n",
    "# Test the advanced selector\n",
    "advanced_selector = AdvancedSpringFeatureSelector(selection_ratio=0.3)\n",
    "selected_features = advanced_selector.select_features_advanced(X, y)\n",
    "\n",
    "print(f\"\\nâœ… Successfully selected {len(selected_features)} features: {selected_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16f4ca9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ RUNNING PUBLICATION-READY EVALUATION\n",
      "============================================================\n",
      "ðŸ“Š LOADING REAL-WORLD DATASETS\n",
      "==================================================\n",
      "   breast_cancer: 30 features, 569 samples\n",
      "   wine: 13 features, 178 samples\n",
      "   iris: 4 features, 150 samples\n",
      "ðŸ“Š COMPREHENSIVE EVALUATION: breast_cancer\n",
      "============================================================\n",
      "ðŸš€ ADVANCED SPRING DYNAMICS FEATURE SELECTION\n",
      "============================================================\n",
      "   Round 1: Selected Feature 20 (Spring: 0.847, Perf: 0.983, Div: 0.500)\n",
      "   Round 2: Selected Feature 7 (Spring: 0.729, Perf: 0.975, Div: 0.062)\n",
      "   Round 3: Selected Feature 0 (Spring: 0.710, Perf: 0.893, Div: 0.016)\n",
      "   Round 4: Selected Feature 3 (Spring: 0.684, Perf: 0.881, Div: 0.006)\n",
      "   Round 5: Selected Feature 27 (Spring: 0.595, Perf: 0.980, Div: 0.041)\n",
      "âœ… Selected 12 features with advanced criteria\n",
      "ðŸ“Š COMPREHENSIVE EVALUATION: wine\n",
      "============================================================\n",
      "ðŸš€ ADVANCED SPRING DYNAMICS FEATURE SELECTION\n",
      "============================================================\n",
      "   Round 1: Selected Feature 5 (Spring: 0.915, Perf: 0.752, Div: 0.900)\n",
      "   Round 2: Selected Feature 6 (Spring: 0.766, Perf: 1.000, Div: 0.076)\n",
      "   Round 3: Selected Feature 12 (Spring: 0.488, Perf: 0.800, Div: 0.346)\n",
      "   Round 4: Selected Feature 11 (Spring: 0.544, Perf: 0.844, Div: 0.145)\n",
      "   Round 5: Selected Feature 8 (Spring: 0.654, Perf: 0.556, Div: 0.265)\n",
      "âœ… Selected 5 features with advanced criteria\n",
      "ðŸ“Š COMPREHENSIVE EVALUATION: iris\n",
      "============================================================\n",
      "ðŸš€ ADVANCED SPRING DYNAMICS FEATURE SELECTION\n",
      "============================================================\n",
      "   Round 1: Selected Feature 2 (Spring: 0.353, Perf: 0.999, Div: 0.818)\n",
      "âœ… Selected 1 features with advanced criteria\n",
      "\n",
      "======================================================================\n",
      "ðŸ“‘ PUBLICATION-READY SPRING DYNAMICS FEATURE SELECTION REPORT\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š DATASET: BREAST_CANCER\n",
      "--------------------------------------------------\n",
      "ðŸŽ¯ Spring Dynamics Performance: 0.9456\n",
      "ðŸ”§ Selected 12 features\n",
      "\n",
      "ðŸ“ˆ COMPARISON WITH TRADITIONAL METHODS:\n",
      "   âœ… ANOVA          : 0.9455 (Difference: +0.0000)\n",
      "   âž– Mutual_Info    : 0.9473 (Difference: -0.0018)\n",
      "   âœ… Random_Forest  : 0.9420 (Difference: +0.0035)\n",
      "   âž– RFE            : 0.9737 (Difference: -0.0281)\n",
      "\n",
      "ðŸ›¡ï¸  ROBUSTNESS ANALYSIS:\n",
      "   Mean Performance: 0.9482\n",
      "   Standard Deviation: 0.0048\n",
      "   Range: 0.9407 - 0.9538\n",
      "\n",
      "ðŸ“Š DATASET: WINE\n",
      "--------------------------------------------------\n",
      "ðŸŽ¯ Spring Dynamics Performance: 0.9108\n",
      "ðŸ”§ Selected 5 features\n",
      "\n",
      "ðŸ“ˆ COMPARISON WITH TRADITIONAL METHODS:\n",
      "   âž– ANOVA          : 0.9610 (Difference: -0.0502)\n",
      "   âž– Mutual_Info    : 0.9610 (Difference: -0.0502)\n",
      "   âž– Random_Forest  : 0.9610 (Difference: -0.0502)\n",
      "   âž– RFE            : 0.9721 (Difference: -0.0613)\n",
      "\n",
      "ðŸ›¡ï¸  ROBUSTNESS ANALYSIS:\n",
      "   Mean Performance: 0.9123\n",
      "   Standard Deviation: 0.0104\n",
      "   Range: 0.9020 - 0.9303\n",
      "\n",
      "ðŸ“Š DATASET: IRIS\n",
      "--------------------------------------------------\n",
      "ðŸŽ¯ Spring Dynamics Performance: 0.9533\n",
      "ðŸ”§ Selected 1 features\n",
      "\n",
      "ðŸ“ˆ COMPARISON WITH TRADITIONAL METHODS:\n",
      "   âž– ANOVA          : 0.9533 (Difference: +0.0000)\n",
      "   âž– Mutual_Info    : 0.9533 (Difference: +0.0000)\n",
      "   âž– Random_Forest  : 0.9533 (Difference: +0.0000)\n",
      "   âž– RFE            : 0.9600 (Difference: -0.0067)\n",
      "\n",
      "ðŸ›¡ï¸  ROBUSTNESS ANALYSIS:\n",
      "   Mean Performance: 0.9533\n",
      "   Standard Deviation: 0.0100\n",
      "   Range: 0.9417 - 0.9667\n"
     ]
    }
   ],
   "source": [
    "class PublicationReadySpringSelector(AdvancedSpringFeatureSelector):\n",
    "    \"\"\"Publication-ready implementation with comprehensive evaluation\"\"\"\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.evaluation_metrics = {}\n",
    "        self.comparison_results = {}\n",
    "    \n",
    "    def comprehensive_evaluation(self, X, y, feature_names, dataset_name, problem_type='classification'):\n",
    "        \"\"\"Run comprehensive evaluation for publication\"\"\"\n",
    "        print(f\"ðŸ“Š COMPREHENSIVE EVALUATION: {dataset_name}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # 1. Run advanced spring selection\n",
    "        spring_features = self.select_features_advanced(X, y, problem_type)\n",
    "        \n",
    "        # 2. Compare with traditional methods\n",
    "        comparison = self.compare_with_traditional_methods(X, y, len(spring_features), problem_type)\n",
    "        \n",
    "        # 3. Robustness analysis\n",
    "        robustness = self.robustness_analysis(X, y, spring_features, problem_type)\n",
    "        \n",
    "        # Store results\n",
    "        self.evaluation_metrics[dataset_name] = {\n",
    "            'spring_features': spring_features,\n",
    "            'comparison': comparison,\n",
    "            'robustness': robustness,\n",
    "            'feature_names': feature_names\n",
    "        }\n",
    "        \n",
    "        return self.evaluation_metrics[dataset_name]\n",
    "    \n",
    "    def compare_with_traditional_methods(self, X, y, n_features, problem_type):\n",
    "        \"\"\"Compare with traditional feature selection methods\"\"\"\n",
    "        comparison_results = {}\n",
    "        \n",
    "        # ANOVA F-test\n",
    "        try:\n",
    "            anova = SelectKBest(f_classif, k=n_features)\n",
    "            anova.fit(X, y)\n",
    "            anova_features = np.argsort(anova.scores_)[-n_features:].tolist()\n",
    "            anova_performance = self.evaluate_features(X, y, anova_features, problem_type)\n",
    "            comparison_results['ANOVA'] = {\n",
    "                'performance': anova_performance,\n",
    "                'features': anova_features\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"   ANOVA failed: {e}\")\n",
    "        \n",
    "        # Mutual Information\n",
    "        try:\n",
    "            mi = SelectKBest(mutual_info_classif, k=n_features)\n",
    "            mi.fit(X, y)\n",
    "            mi_features = np.argsort(mi.scores_)[-n_features:].tolist()\n",
    "            mi_performance = self.evaluate_features(X, y, mi_features, problem_type)\n",
    "            comparison_results['Mutual_Info'] = {\n",
    "                'performance': mi_performance,\n",
    "                'features': mi_features\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"   Mutual Info failed: {e}\")\n",
    "        \n",
    "        # Random Forest\n",
    "        try:\n",
    "            rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            rf.fit(X, y)\n",
    "            rf_features = np.argsort(rf.feature_importances_)[-n_features:].tolist()\n",
    "            rf_performance = self.evaluate_features(X, y, rf_features, problem_type)\n",
    "            comparison_results['Random_Forest'] = {\n",
    "                'performance': rf_performance,\n",
    "                'features': rf_features\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"   Random Forest failed: {e}\")\n",
    "        \n",
    "        # RFE (Recursive Feature Elimination)\n",
    "        try:\n",
    "            if problem_type == 'classification':\n",
    "                estimator = LogisticRegression(random_state=42)\n",
    "            else:\n",
    "                from sklearn.linear_model import LinearRegression\n",
    "                estimator = LinearRegression()\n",
    "            \n",
    "            rfe = RFE(estimator=estimator, n_features_to_select=n_features)\n",
    "            rfe.fit(X, y)\n",
    "            rfe_features = np.where(rfe.support_)[0].tolist()\n",
    "            rfe_performance = self.evaluate_features(X, y, rfe_features, problem_type)\n",
    "            comparison_results['RFE'] = {\n",
    "                'performance': rfe_performance,\n",
    "                'features': rfe_features\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"   RFE failed: {e}\")\n",
    "        \n",
    "        return comparison_results\n",
    "    \n",
    "    def evaluate_features(self, X, y, features, problem_type):\n",
    "        \"\"\"Evaluate feature set performance\"\"\"\n",
    "        if len(features) == 0:\n",
    "            return 0\n",
    "        \n",
    "        if problem_type == 'classification':\n",
    "            model = LogisticRegression(random_state=42)\n",
    "            scores = cross_val_score(model, X[:, features], y, cv=5, scoring='accuracy')\n",
    "            return scores.mean()\n",
    "        else:\n",
    "            from sklearn.linear_model import LinearRegression\n",
    "            model = LinearRegression()\n",
    "            scores = cross_val_score(model, X[:, features], y, cv=5, scoring='r2')\n",
    "            return scores.mean()\n",
    "    \n",
    "    def robustness_analysis(self, X, y, features, problem_type, n_splits=5):\n",
    "        \"\"\"Analyze robustness across different data splits\"\"\"\n",
    "        from sklearn.model_selection import KFold\n",
    "        \n",
    "        performances = []\n",
    "        \n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        \n",
    "        for train_idx, test_idx in kf.split(X):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            \n",
    "            # Train model on selected features\n",
    "            performance = self.evaluate_features(X_train, y_train, features, problem_type)\n",
    "            performances.append(performance)\n",
    "        \n",
    "        robustness_metrics = {\n",
    "            'mean_performance': np.mean(performances),\n",
    "            'std_performance': np.std(performances),\n",
    "            'min_performance': np.min(performances),\n",
    "            'max_performance': np.max(performances)\n",
    "        }\n",
    "        \n",
    "        return robustness_metrics\n",
    "    \n",
    "    def generate_publication_report(self):\n",
    "        \"\"\"Generate comprehensive publication report\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ðŸ“‘ PUBLICATION-READY SPRING DYNAMICS FEATURE SELECTION REPORT\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        for dataset_name, results in self.evaluation_metrics.items():\n",
    "            print(f\"\\nðŸ“Š DATASET: {dataset_name.upper()}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            # Get spring dynamics performance\n",
    "            spring_perf = self.evaluate_features(\n",
    "                self.datasets[dataset_name]['X'], \n",
    "                self.datasets[dataset_name]['y'],\n",
    "                results['spring_features'],\n",
    "                self.datasets[dataset_name]['problem_type']\n",
    "            )\n",
    "            \n",
    "            print(f\"ðŸŽ¯ Spring Dynamics Performance: {spring_perf:.4f}\")\n",
    "            print(f\"ðŸ”§ Selected {len(results['spring_features'])} features\")\n",
    "            \n",
    "            print(f\"\\nðŸ“ˆ COMPARISON WITH TRADITIONAL METHODS:\")\n",
    "            for method_name, method_results in results['comparison'].items():\n",
    "                perf_diff = spring_perf - method_results['performance']\n",
    "                comparison_symbol = \"âœ…\" if perf_diff > 0 else \"âž–\"\n",
    "                print(f\"   {comparison_symbol} {method_name:<15}: {method_results['performance']:.4f} \"\n",
    "                      f\"(Difference: {perf_diff:+.4f})\")\n",
    "            \n",
    "            print(f\"\\nðŸ›¡ï¸  ROBUSTNESS ANALYSIS:\")\n",
    "            robustness = results['robustness']\n",
    "            print(f\"   Mean Performance: {robustness['mean_performance']:.4f}\")\n",
    "            print(f\"   Standard Deviation: {robustness['std_performance']:.4f}\")\n",
    "            print(f\"   Range: {robustness['min_performance']:.4f} - {robustness['max_performance']:.4f}\")\n",
    "\n",
    "# Create dataset tester\n",
    "class RealWorldDatasetTester:\n",
    "    def __init__(self):\n",
    "        self.datasets = {}\n",
    "    \n",
    "    def load_real_datasets(self):\n",
    "        \"\"\"Load multiple real-world datasets\"\"\"\n",
    "        print(\"ðŸ“Š LOADING REAL-WORLD DATASETS\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Classification datasets\n",
    "        datasets_to_load = {\n",
    "            'breast_cancer': load_breast_cancer(),\n",
    "            'wine': load_wine(), \n",
    "            'iris': load_iris()\n",
    "        }\n",
    "        \n",
    "        for name, dataset in datasets_to_load.items():\n",
    "            X, y = dataset.data, dataset.target\n",
    "            \n",
    "            # Handle feature names\n",
    "            if hasattr(dataset, 'feature_names'):\n",
    "                feature_names = list(dataset.feature_names)\n",
    "            else:\n",
    "                feature_names = [f'feature_{i}' for i in range(X.shape[1])]\n",
    "            \n",
    "            # Standardize features\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "            \n",
    "            self.datasets[name] = {\n",
    "                'X': X_scaled,\n",
    "                'y': y,\n",
    "                'feature_names': feature_names,\n",
    "                'problem_type': 'classification'\n",
    "            }\n",
    "            \n",
    "            print(f\"   {name}: {X.shape[1]} features, {X.shape[0]} samples\")\n",
    "        \n",
    "        return self.datasets\n",
    "\n",
    "# Run the complete publication-ready evaluation\n",
    "print(\"\\nðŸ“ RUNNING PUBLICATION-READY EVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load datasets\n",
    "tester = RealWorldDatasetTester()\n",
    "tester.load_real_datasets()\n",
    "\n",
    "# Create publication selector\n",
    "publication_selector = PublicationReadySpringSelector(\n",
    "    performance_weight=0.3,\n",
    "    diversity_weight=0.2,\n",
    "    selection_ratio=0.4\n",
    ")\n",
    "\n",
    "# Add datasets to publication selector for reporting\n",
    "publication_selector.datasets = tester.datasets\n",
    "\n",
    "# Test on multiple datasets\n",
    "for dataset_name, data in tester.datasets.items():\n",
    "    publication_selector.comprehensive_evaluation(\n",
    "        data['X'], data['y'], \n",
    "        data['feature_names'], dataset_name,\n",
    "        data['problem_type']\n",
    "    )\n",
    "\n",
    "# Generate final report\n",
    "publication_selector.generate_publication_report()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
